/**
 * Abstract superclass for all "scrapers"
 */

import {
    AlbumEntity,
    ArtistEntity,
    GenreEntity,
    ProfileEntity,
} from '../entities/index';
import {
    Log,
    ResultBatch,
    ScrapeResult,
} from '../helpers/classes/index';

/**
 * Abstract superclass for all "scrapers"
 *
 * @remarks
 * This abstract class describes a standardized method of scraping web pages and saving the
 * results. Its structure is specifically engineered to support complex, relational data stored
 * in a RDBMS such as Postgres. An subclass of AbstractScraper generally describes the process of
 * scraping one type of webpage into one database table. Each instance of a class extending
 * AbstractScraper corresponds to the scrape of one specific URL. The general use pattern for an
 * instance of such as class is to first call the constructor, then [[AbstractScraper.scrape]].
 */
export abstract class AbstractScraper {
    /**
     * Primary key of the database record corresponding to a given scraper instance. This will
     * always be set after [[AbstractScraper.scrape]] is called, provided that no error was thrown.
     */
    public databaseID: number;

    /**
     * Scrapers always check for a local copy of the target resource (using
     * [[AbstractScraper.getEntity]]) before executing a scrape from an external resource. If the
     * resource was found (and therefore no external calls made), this flag is set to true.
     */
    public dataReadFromDB: boolean;

    /**
     * Contains all results generated by [[AbstractScraper.scrape]], including recursive calls.
     */
    public results: ResultBatch;

    /**
     * A simple, human-readble description of *what* is being scraped. Used for logging.
     */
    public scrapeContentDescription: string;

    /**
     * External url indicating the scraper's target resource.
     */
    public url: string;

    /**
     * Used to override .env settings and force-log the output of a given scraper.
     */
    public verbose: boolean;

    /**
     * Flag indicating a sucessful scrape, set to true after non-error-throwing call to
     * [[AbstractScraper.scrape]].
     */
    public scrapeSucceeded: boolean;

    /**
     * @param url see [[AbstractScraper.url]]
     * @param scrapeContentDescription see [[AbstractScraper.scrapeContentDescription]]
     * @param verbose see [[AbstractScraper.verbose]]
     */
    public constructor(
        url: string,
        scrapeContentDescription: string,
        verbose?: boolean,
    ) {
        this.url = url;
        this.verbose = verbose || false;
        this.scrapeContentDescription = scrapeContentDescription;
        this.results = new ResultBatch();
        this.dataReadFromDB = false;
        this.scrapeSucceeded = false;
    }

    /**
     * Entry point for initiating an asset scrape. General scrape outline/method order:
     *
     * 1. **[[AbstractScraper.getEntity]]**
     *
     *    Attempt to retrieve a local copy. If found, update class props and return.
     *
     * 2. **[[requestRawScrape]]**
     *
     *    Initialize a request for some asset you want to scrape
     *
     * 3. **[[AbstractScraper.extractInfo]]**
     *
     *    Extract information from the requested resource, and store it in local props
     *
     * @param forceScrape If set to true, scrapes the external resource regardless of any existing
     * local records
     */
    public async scrape(forceScrape = false): Promise<void> {
        Log.notify(`Beginning Scrape of ${this.scrapeContentDescription}`);
        let saved = await this.getEntity();
        if(saved && !forceScrape) {
            this.dataReadFromDB = true;
            this.databaseID = saved.id;
            this.results.push(new ScrapeResult(true, this.url));
            this.scrapeSucceeded = true;
            Log.success(`Local Record Found for ${this.scrapeContentDescription}`);
            return;
        }
        await this.requestScrape();
        this.extractInfo();
        await this.scrapeDependencies();

        saved = await this.saveToDB();
        this.databaseID = saved.id;
        this.results.push(new ScrapeResult(true, this.url));
        this.scrapeSucceeded = true;
        Log.success(`Finished Scrape of ${this.scrapeContentDescription}`);
    }

    public printResult(): void {
        if(this.scrapeSucceeded === false) {
            Log.err(`Scrape failed for album url:\n${this.url}`);
        } else if(this.dataReadFromDB) {
            Log.success(
                `Scrape unnecessary, record exists in database\nURL: ${this.url}\nID: ${this.databaseID}`,
            );
        } else {
            Log.success(
                `Scrape successful\nURL: ${this.url}\nID: ${this.databaseID}`,
            );
        }
    }

    protected abstract extractInfo(): void;

    public abstract getEntity(): Promise<
    AlbumEntity
    | ArtistEntity
    | GenreEntity
    | ProfileEntity
    >;

    public abstract requestScrape(): Promise<void>;

    public abstract printInfo(): void;

    protected abstract async saveToDB(): Promise<
    AlbumEntity
    | ArtistEntity
    | GenreEntity
    | ProfileEntity
    >;

    protected abstract async scrapeDependencies(): Promise<void>;
}
